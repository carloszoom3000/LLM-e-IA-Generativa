{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10050814,"sourceType":"datasetVersion","datasetId":6192674}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Modelo Grande de Lenguaje (LLM) e IA Generativa\n\nTP Clase 6\n\nCarlos Villalobos","metadata":{}},{"cell_type":"code","source":"!pip install langchain pypdf faiss-cpu sentence-transformers transformers torch\n!pip install -U langchain-community\n!pip install langchain_groq\n!pip install gradio langchain pypdf faiss-cpu langchain_groq transformers torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T13:55:41.497676Z","iopub.execute_input":"2024-11-29T13:55:41.498012Z","iopub.status.idle":"2024-11-29T13:56:28.892704Z","shell.execute_reply.started":"2024-11-29T13:55:41.497983Z","shell.execute_reply":"2024-11-29T13:56:28.891815Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain\n  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (5.0.1)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nCollecting sentence-transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nCollecting langchain-core<0.4.0,>=0.3.21 (from langchain)\n  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\nCollecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.9.2)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\nRequirement already satisfied: typing_extensions>=4.0 in /opt/conda/lib/python3.10/site-packages (from pypdf) (4.12.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (21.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\nCollecting packaging (from faiss-cpu)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\nCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (2.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\nDownloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\nDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, requests-toolbelt, faiss-cpu, langsmith, langchain-core, sentence-transformers, langchain-text-splitters, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: requests-toolbelt\n    Found existing installation: requests-toolbelt 0.10.1\n    Uninstalling requests-toolbelt-0.10.1:\n      Successfully uninstalled requests-toolbelt-0.10.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.3 requires cubinlinker, which is not installed.\ncudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed faiss-cpu-1.9.0.post1 langchain-0.3.9 langchain-core-0.3.21 langchain-text-splitters-0.3.2 langsmith-0.1.147 packaging-24.2 requests-toolbelt-1.0.0 sentence-transformers-3.3.1\nCollecting langchain-community\n  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.9.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.7)\nCollecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: langchain<0.4.0,>=0.3.8 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.9)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.21)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.1.147)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (1.26.4)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (8.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.8->langchain-community) (0.3.2)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.8->langchain-community) (2.9.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.4)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-community) (2.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain-community) (2.23.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.0)\nDownloading langchain_community-0.3.8-py3-none-any.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\nInstalling collected packages: httpx-sse, pydantic-settings, langchain-community\nSuccessfully installed httpx-sse-0.4.0 langchain-community-0.3.8 pydantic-settings-2.6.1\nCollecting langchain_groq\n  Downloading langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting groq<1,>=0.4.1 (from langchain_groq)\n  Downloading groq-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from langchain_groq) (0.3.21)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (4.4.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (2.9.2)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (6.0.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (0.1.147)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (24.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (8.3.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_groq) (2.4)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (3.10.4)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (2.32.3)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (1.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (1.26.18)\nDownloading langchain_groq-0.2.1-py3-none-any.whl (14 kB)\nDownloading groq-0.12.0-py3-none-any.whl (108 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: groq, langchain_groq\nSuccessfully installed groq-0.12.0 langchain_groq-0.2.1\nCollecting gradio\n  Downloading gradio-5.7.1-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.3.9)\nRequirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (5.0.1)\nRequirement already satisfied: faiss-cpu in /opt/conda/lib/python3.10/site-packages (1.9.0.post1)\nRequirement already satisfied: langchain_groq in /opt/conda/lib/python3.10/site-packages (0.2.1)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.4.0)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting gradio-client==1.5.0 (from gradio)\n  Downloading gradio_client-1.5.0-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\nRequirement already satisfied: huggingface-hub>=0.25.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.4)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.5)\nRequirement already satisfied: numpy<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.10.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (24.2)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.2)\nRequirement already satisfied: pillow<12.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.3.0)\nRequirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.9.2)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nCollecting python-multipart==0.0.12 (from gradio)\n  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0.2)\nCollecting ruff>=0.2.2 (from gradio)\n  Downloading ruff-0.8.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<1.0,>=0.1.1 (from gradio)\n  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\nCollecting tomlkit==0.12.0 (from gradio)\n  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.3)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.12.2)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.30.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.5.0->gradio) (2024.6.1)\nRequirement already satisfied: websockets<13.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.5.0->gradio) (12.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.3.21)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.3.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.147)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\nRequirement already satisfied: groq<1,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from langchain_groq) (0.12.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (2.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-5.7.1-py3-none-any.whl (57.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.5.0-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\nDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\nDownloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ruff-0.8.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\nInstalling collected packages: tomlkit, semantic-version, ruff, python-multipart, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\n  Attempting uninstall: tomlkit\n    Found existing installation: tomlkit 0.13.2\n    Uninstalling tomlkit-0.13.2:\n      Successfully uninstalled tomlkit-0.13.2\n  Attempting uninstall: python-multipart\n    Found existing installation: python-multipart 0.0.9\n    Uninstalling python-multipart-0.0.9:\n      Successfully uninstalled python-multipart-0.0.9\n  Attempting uninstall: starlette\n    Found existing installation: starlette 0.37.2\n    Uninstalling starlette-0.37.2:\n      Successfully uninstalled starlette-0.37.2\n  Attempting uninstall: fastapi\n    Found existing installation: fastapi 0.111.0\n    Uninstalling fastapi-0.111.0:\n      Successfully uninstalled fastapi-0.111.0\nSuccessfully installed fastapi-0.115.5 ffmpy-0.4.0 gradio-5.7.1 gradio-client-1.5.0 python-multipart-0.0.12 ruff-0.8.1 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.12.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoModel\n\nembedding_model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T13:57:13.967085Z","iopub.execute_input":"2024-11-29T13:57:13.967451Z","iopub.status.idle":"2024-11-29T13:57:26.724259Z","shell.execute_reply.started":"2024-11-29T13:57:13.967414Z","shell.execute_reply":"2024-11-29T13:57:26.723433Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca0fa427b37b425abf424155a6d3d219"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_bert.py:   0%|          | 0.00/8.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1835891366654b69a8e4f519abfeb723"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-bert-implementation:\n- configuration_bert.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_bert.py:   0%|          | 0.00/97.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d54cd0459d64dcd9bc78cc7517a96b9"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-bert-implementation:\n- modeling_bert.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/275M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"442c3b0b54a84fc4b9ea245e748c87b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/373 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e914f576a074343a9e4a2cfc29a98c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"300e7ec195c84bb9b6b3611d660aa3cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19b606c8dd16437ba13fe017ce05fd56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afd9bff8ae37413180393a4be0d567b9"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_groq import ChatGroq\nfrom langchain_core.prompts import ChatPromptTemplate\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\nimport faiss\nimport numpy as np\nimport os\n\nclass JinaEmbeddings:\n    def __init__(self):\n        \"\"\"Initialize the Jina embeddings model\"\"\"\n        self.model_name = \"jinaai/jina-embeddings-v2-base-en\"\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.model = AutoModel.from_pretrained(self.model_name)\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.model.to(self.device)\n        \n    def encode(self, texts):\n        \"\"\"\n        Encode texts to embeddings\n        \n        Args:\n            texts (str or list): Text or list of texts to encode\n            \n        Returns:\n            numpy.ndarray: Embeddings\n        \"\"\"\n        # Asegurar que el texto existe\n        if isinstance(texts, str):\n            texts = [texts]\n            \n        # Tokenizar y obtener las salidas del modelo\n        encoded_input = self.tokenizer(\n            texts,\n            padding=True,\n            truncation=True,\n            max_length=512,\n            return_tensors='pt'\n        ).to(self.device)\n        \n        with torch.no_grad():\n            model_output = self.model(**encoded_input)\n            \n        # Mean pooling\n        attention_mask = encoded_input['attention_mask']\n        token_embeddings = model_output[0]\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n        embeddings = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n        \n        return embeddings.cpu().numpy()\n\nclass DocumentQA:\n    def __init__(self, pdf_path, groq_api_key):\n        \"\"\"\n        Initialize the Document QA system\n        \n        Args:\n            pdf_path (str): Path to the PDF document\n            groq_api_key (str): Groq API key\n        \"\"\"\n        self.pdf_path = pdf_path\n        self.vector_store = None\n        self.jina_embeddings = JinaEmbeddings()\n        \n        # Inicializar Groq LLM\n        os.environ[\"GROQ_API_KEY\"] = groq_api_key\n        self.llm = ChatGroq(\n            model_name=\"mixtral-8x7b-32768\",\n            temperature=0.3,\n            max_tokens=1000\n        )\n        \n        # Crear un template de QA prompt\n        self.qa_prompt = ChatPromptTemplate.from_messages([\n            (\"system\", \"\"\"You are a helpful assistant that answers questions based on the provided context. \n            Your answers should be:\n            1. Accurate and based solely on the provided context\n            2. Comprehensive yet concise\n            3. Well-structured and easy to understand\n            If the context doesn't contain enough information to answer the question, say so.\n            \n            Context: {context}\"\"\"),\n            (\"human\", \"{question}\")\n        ])\n        \n    def load_and_split_document(self):\n        \"\"\"Load PDF and split into chunks\"\"\"\n        # Cargar el PDF\n        loader = PyPDFLoader(self.pdf_path)\n        documents = loader.load()\n        \n        # Dividir el texto enchunks\n        text_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=1000,\n            chunk_overlap=200,\n            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n        )\n        self.chunks = text_splitter.split_documents(documents)\n        return self.chunks\n    \n    def create_vector_store(self):\n        \"\"\"Create FAISS vector store from document chunks\"\"\"\n        # Extraer el texto de los chunks\n        texts = [doc.page_content for doc in self.chunks]\n        \n        # Generar los embeddings\n        embeddings = self.jina_embeddings.encode(texts)\n        \n        # Crear el indice FAISS\n        dimension = embeddings.shape[1]\n        index = faiss.IndexFlatL2(dimension)\n        index.add(embeddings)\n        \n        # Guardar el documento en chunks y crear el retriever\n        self.vector_store = {\n            'index': index,\n            'documents': self.chunks,\n            'embeddings': embeddings\n        }\n        return self.vector_store\n    \n    def retrieve_similar_chunks(self, query, k=3):\n        \"\"\"\n        Retrieve similar chunks for a query\n        \n        Args:\n            query (str): Query text\n            k (int): Number of chunks to retrieve\n            \n        Returns:\n            list: Similar document chunks\n        \"\"\"\n        # Generar la query de embedding\n        query_embedding = self.jina_embeddings.encode(query)\n        \n        # Buscar los vectores similares\n        distances, indices = self.vector_store['index'].search(query_embedding, k)\n        \n        # Devolver los documentos que corresponder\n        similar_docs = [self.vector_store['documents'][i] for i in indices[0]]\n        return similar_docs\n    \n    def generate_answer(self, question, context_docs):\n        \"\"\"\n        Generate answer using Groq LLM\n        \n        Args:\n            question (str): Question to answer\n            context_docs (list): List of relevant document chunks\n            \n        Returns:\n            str: Generated answer\n        \"\"\"\n        # Combinar el contexto de los documentos obtenidos\n        context = \"\\n\".join([doc.page_content for doc in context_docs])\n        \n        # Dar formato al prompt con context y question\n        formatted_prompt = self.qa_prompt.format_messages(\n            context=context,\n            question=question\n        )\n        \n        # Generar la respuesta usando Groq\n        response = self.llm.invoke(formatted_prompt)\n        return response.content\n    \n    def initialize_system(self):\n        \"\"\"Initialize the complete system\"\"\"\n        print(\"Loading and splitting document...\")\n        self.load_and_split_document()\n        print(\"Creating vector store...\")\n        self.create_vector_store()\n        print(\"System initialized!\")\n    \n    def ask_question(self, question):\n        \"\"\"\n        Ask a question to the system\n        \n        Args:\n            question (str): Question to ask\n            \n        Returns:\n            dict: Contains answer and source documents\n        \"\"\"\n        if not self.vector_store:\n            raise ValueError(\"System not initialized. Call initialize_system() first.\")\n        \n        # Recuperar los chunks relevantes\n        similar_docs = self.retrieve_similar_chunks(question)\n        \n        # Generar respuesta usando Groq\n        answer = self.generate_answer(question, similar_docs)\n        \n        return {\n            \"answer\": answer,\n            \"sources\": [doc.page_content for doc in similar_docs]\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T13:57:41.863992Z","iopub.execute_input":"2024-11-29T13:57:41.864466Z","iopub.status.idle":"2024-11-29T13:57:42.826451Z","shell.execute_reply.started":"2024-11-29T13:57:41.864411Z","shell.execute_reply":"2024-11-29T13:57:42.825570Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Ejemplo de uso\ndef main():\n    # Incializa el sistema\n    pdf_path = \"/kaggle/input/curriculum/cv.pdf\"\n    groq_api_key = \"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\"  # Aqui va la Groq API key\n    \n    qa_system = DocumentQA(pdf_path, groq_api_key)\n    qa_system.initialize_system()\n    \n    # Ejemplo de preguntas\n    questions = [\n        \"What is your Professional Summary?\",\n        \"What is your Technical Expertise?\",\n        \"What are your Certifications?\",\n        \"\"\n    ]\n    \n    # Get answers\n    for question in questions:\n        print(f\"\\nQuestion: {question}\")\n        print(\"Generating answer...\")\n        result = qa_system.ask_question(question)\n        print(f\"Answer: {result['answer']}\")\n        print(\"\\nSources:\")\n        for i, source in enumerate(result['sources'], 1):\n            print(f\"Source {i}: {source[:200]}...\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T13:59:27.952331Z","iopub.execute_input":"2024-11-29T13:59:27.952649Z","iopub.status.idle":"2024-11-29T13:59:31.155362Z","shell.execute_reply.started":"2024-11-29T13:59:27.952624Z","shell.execute_reply":"2024-11-29T13:59:31.154158Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nBertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n","output_type":"stream"},{"name":"stdout","text":"Loading and splitting document...\nCreating vector store...\nSystem initialized!\n\nQuestion: What is your Professional Summary?\nGenerating answer...\nAnswer: The provided context includes a profile summary for Carlos Villalobos, an Electronics and Telecommunication Engineer with extensive experience in AI, computer vision, and technical solutions. Carlos is adept at developing innovative solutions to complex problems, collaborating across teams, and driving projects from concept to deployment. He has strong expertise in AI modeling, REST API development, and cloud integrations. Key skills include programming languages such as Python, JavaScript, and HTML/CSS, as well as experience with cloud technologies, web monitoring and logging, database management, and team collaboration.\n\nSources:\nSource 1: •Conducted diagnostics and preventive maintenance for advanced telecommunication systems.•Spearheaded projects to enhance operational efﬁciency, reducing downtime by 15%.•Collaborated with cross-disci...\nSource 2: – Associate•Advanced Python for Data Science and AI, [Institution]•Google Cloud Professional Data EngineerKey ProjectsSmart Dressing Room (AI-Powered Wardrobe Assistant)•Developed a computer vision mo...\nSource 3: Carlos Villalobos[Your Address] | [Your Phone Number] | [Your Email Address] | [LinkedIn Proﬁle] | [GitHub Proﬁle]Page 1: Proﬁle & Key SkillsProfessional SummaryResults-driven Electronics and Telecomm...\n\nQuestion: What is your Technical Expertise?\nGenerating answer...\nAnswer: The provided context indicates that the individual has technical expertise in the following areas:\n\n1. REST API queries and platform integrations\n2. Advanced knowledge in electronics and telecommunication systems\n3. AI specialization, with project experience in smart dressing rooms\n\nThese expertise areas are based on the direct statements in the context, and further information is not provided to expand on this section.\n\nSources:\nSource 1: Management: SQL with PostgreSQL•Team Collaboration: Training, leadership, cross-functional meetingsTechnical Expertise•REST API queries and platform integrations•Advanced knowledge in electronics and ...\nSource 2: •Conducted diagnostics and preventive maintenance for advanced telecommunication systems.•Spearheaded projects to enhance operational efﬁciency, reducing downtime by 15%.•Collaborated with cross-disci...\nSource 3: – Associate•Advanced Python for Data Science and AI, [Institution]•Google Cloud Professional Data EngineerKey ProjectsSmart Dressing Room (AI-Powered Wardrobe Assistant)•Developed a computer vision mo...\n\nQuestion: What are your Certifications?\nGenerating answer...\nAnswer: Based on the provided context, Carlos Villalobos has the following certifications:\n\n1. AWS Certified Solutions Architect – Associate\n2. Advanced Python for Data Science and AI from an unspecified institution\n3. Google Cloud Professional Data Engineer\n\nSources:\nSource 1: •Conducted diagnostics and preventive maintenance for advanced telecommunication systems.•Spearheaded projects to enhance operational efﬁciency, reducing downtime by 15%.•Collaborated with cross-disci...\nSource 2: – Associate•Advanced Python for Data Science and AI, [Institution]•Google Cloud Professional Data EngineerKey ProjectsSmart Dressing Room (AI-Powered Wardrobe Assistant)•Developed a computer vision mo...\nSource 3: Carlos Villalobos[Your Address] | [Your Phone Number] | [Your Email Address] | [LinkedIn Proﬁle] | [GitHub Proﬁle]Page 1: Proﬁle & Key SkillsProfessional SummaryResults-driven Electronics and Telecomm...\n\nQuestion: \nGenerating answer...\nAnswer: Based on the provided context, Carlos Villalobos is a results-driven Electronics and Telecommunication Engineer with expertise in AI, computer vision, and technical solutions. He has strong skills in programming languages such as Python, JavaScript, and HTML/CSS, as well as experience with AI and machine learning, particularly in computer vision and data modeling. Carlos is also knowledgeable in cloud technologies including AWS S3, Google Cloud, and Blackboard Learn SAML Integration. He has demonstrated technical expertise in REST API queries and platform integrations, advanced knowledge in electronics and telecommunication systems, and an AI specialization with project experience in smart dressing rooms.\n\nIn terms of professional experience, Carlos has worked as a Technical Solutions Engineer for an Education Platform, where he designed and implemented REST API solutions, delivered support for SaaS products, and provided training sessions for internal teams on AI and cloud-based tools. He has also worked as a Maintenance Engineer in the Oil and Gas industry, conducting diagnostics and preventive maintenance for advanced telecommunication systems, collaborating with cross-disciplinary teams for system upgrades and installations, and reducing downtime by 15%. Additionally, Carlos has experience as a Frequency Spectrum Monitoring Specialist for a Telecom Regulatory Body, utilizing advanced frequency analysis tools, developing automation scripts, and leading weekly briefings with stakeholders on spectrum management strategies.\n\nCarlos has a Bachelor of Science in Electronics and Telecommunication Engineering and holds certifications as an AWS Certified Solutions Architect – Associate, Advanced Python for Data Science and AI, and Google Cloud Professional Data Engineer. He has also worked on a key project, developing a smart dressing room powered by AI.\n\nSources:\nSource 1: Carlos Villalobos[Your Address] | [Your Phone Number] | [Your Email Address] | [LinkedIn Proﬁle] | [GitHub Proﬁle]Page 1: Proﬁle & Key SkillsProfessional SummaryResults-driven Electronics and Telecomm...\nSource 2: Management: SQL with PostgreSQL•Team Collaboration: Training, leadership, cross-functional meetingsTechnical Expertise•REST API queries and platform integrations•Advanced knowledge in electronics and ...\nSource 3: •Conducted diagnostics and preventive maintenance for advanced telecommunication systems.•Spearheaded projects to enhance operational efﬁciency, reducing downtime by 15%.•Collaborated with cross-disci...\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}